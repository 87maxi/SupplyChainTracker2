# .aider.config.yml optimizado para LLMs locales y precisión

# Configuración de Conexión
openai-api-base: http://192.168.0.50:8080/v1
openai-api-key: no-key

# Selección de Modelo (esto ayuda a Aider a aplicar sus "instrucciones de edición")
model: openai/Qwen2.5-Coder-14B-Instruct-Q6_K_L.gguf


# --- MEJORA DE PRECISIÓN Y CONTROL ---

# Forzar el formato de edición: 
# Los modelos locales a veces fallan con "diff". 
# "whole" es más lento pero mucho más preciso para modelos de 14B.
# "architect" es ideal si quieres que razone antes de actuar.
edit-format: diff-fenced  # CAMBIO CLAVE: Usa bloques de código delimitados
architect: true
chat-language: spanish

read: [.aider.instructions.md]

# Optimización de respuesta

cache-prompts: true
# Mapa del repositorio: Crucial para "analizar funcionalidades"
# Esto envía una estructura reducida de todo el proyecto al modelo.


# Sugerir cambios en lugar de aplicarlos directamente si notas imprecisión
# auto-test: true
# read: [CONVENTIONS.md] # Si tienes un archivo de reglas de código

# --- INTERFAZ Y LOGS ---
dark-mode: true
show-diffs: true